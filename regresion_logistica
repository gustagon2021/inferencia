# 1. Importar librerías
import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
from beautifultable import BeautifulTable as BT

from sklearn.model_selection import train_test_split as separar
from sklearn.preprocessing import MinMaxScaler

# BLOQUE 2
ruta_archivo = "diabetes.csv" 

# Cargar el dataset desde la ruta local
datos = pd.read_csv(ruta_archivo, encoding='latin1', delimiter=',') 
print(datos.head(10))

# BLOQUE 3
# 3. Crear variable y respuesta
X = datos.iloc[:, 1:-1].values
y = datos['Outcome'].values

# BLOQUE 4
# 4. Variables categóricas! --> Encode
'''
from sklearn.preprocessing import LabelEncoder
encoder = LabelEncoder()
X[:,0] = encoder.fit_transform(X[:,0])
'''
dataframe = pd.DataFrame(X)
print(dataframe.head())

# BLOQUE 5
# 4. Separar en Entrenamiento y Validación
X_train, X_test, y_train, y_test = separar(X, y, test_size=0.25, random_state=0)
print('La forma de X_train es: ', X_train.shape)
print('La forma de y_train es: ', y_train.shape)
print('La forma de X_test es: ', X_test.shape)
print('La forma de y_test es: ', y_test.shape)

# BLOQUE 6
# 5. Escalar los datos
escaladorX = MinMaxScaler()
X_train = escaladorX.fit_transform(X_train.astype('float64'))
X_test  = escaladorX.transform(X_test.astype('float64'))
print(X_test[:5, :])

# BLOQUE 7
# 6. Ajustar el Modelo
from sklearn.linear_model import LogisticRegression as LR
clasificador = LR(random_state=0)
clasificador.fit(X_train, y_train)

# BLOQUE 8
# 7. Hacer las predicciones
y_pred = clasificador.predict(X_test)

# BLOQUE 9
# 8. Crear la Matriz de Confusión para evaluar la clasificación realizada
from sklearn.metrics import confusion_matrix as CM
cm = CM(y_test, y_pred)
print(cm)

# BLOQUE 10
# 9. Visualizar los resultados (reducimos a 2D para visualización)
from sklearn.decomposition import PCA
pca = PCA(n_components=2)
X_train_2D = pca.fit_transform(X_train)
X_test_2D = pca.transform(X_test)

# 9.1 Conjunto de entrenamiento
from matplotlib.colors import ListedColormap as Colors
X_set, y_set = X_train_2D, y_train
X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),
                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))
plt.contourf(X1, X2, clasificador.predict(pca.inverse_transform(np.array([X1.ravel(), X2.ravel()]).T)).reshape(X1.shape),
             alpha = 0.5, cmap = Colors(('red', 'green')))
plt.xlim(X1.min(), X1.max())
plt.ylim(X2.min(), X2.max())
for i, j in enumerate(np.unique(y_set)):
    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],
                c = Colors(('red', 'green'))(i), label = j, s=10)
plt.title('Clasificación con Regresión Logística (Conjunto de entrenamiento)')
plt.xlabel('Componente Principal 1')
plt.ylabel('Componente Principal 2')
plt.legend()
plt.show()

# 9.2 Conjunto de validación
X_set, y_set = X_test_2D, y_test
X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),
                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))
plt.contourf(X1, X2, clasificador.predict(pca.inverse_transform(np.array([X1.ravel(), X2.ravel()]).T)).reshape(X1.shape),
             alpha = 0.5, cmap = Colors(('red', 'green')))
plt.xlim(X1.min(), X1.max())
plt.ylim(X2.min(), X2.max())
for i, j in enumerate(np.unique(y_set)):
    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],
                c = Colors(('red', 'green'))(i), label = j, s=10)
plt.title('Clasificación con Regresión Logística (Conjunto de validación)')
plt.xlabel('Componente Principal 1')
plt.ylabel('Componente Principal 2')
plt.legend()
plt.show()
